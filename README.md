# üß† ProcessON - I2A2

Este projeto oferece uma interface interativa para processar e consultar dados de m√∫ltiplos arquivos CSV contidos em um arquivo ZIP. Ele aproveita o poder dos Modelos de Linguagem Grandes (LLMs) via biblioteca `dspy` para responder a perguntas em linguagem natural sobre os dados carregados, e `Gradio` para uma interface web amig√°vel.

---

## üéØ Contexto do Desafio I2A2

Esta atividade faz parte do curso I2A2 e tem como objetivo principal **criar um ou mais agentes que permitam a um usu√°rio realizar perguntas sobre arquivos CSV disponibilizados**.

Por exemplo, os usu√°rios podem perguntar:
* "Qual √© o fornecedor que teve maior montante recebido?"
* "Qual item teve maior volume entregue (em quantidade)?"
* E assim por diante, explorando os dados de forma conversacional.

### Recursos Utilizados

Para este desafio, √© fornecido um arquivo chamado `202401_NFs.zip`. Este arquivo cont√©m:

* **`202401_NFs_Cabecalho.csv`**: O cabe√ßalho de 100 notas fiscais selecionadas aleatoriamente do arquivo de notas fiscais do m√™s de janeiro/2024, disponibilizado pelo Tribunal de Contas da Uni√£o.
* **`202401_NFs_Itens.csv`**: Os itens correspondentes das 100 notas fiscais selecionadas.

---

## üöÄ Primeiros Passos

Siga estas instru√ß√µes para configurar e executar o projeto localmente.

### Pr√©-requisitos

Antes de come√ßar, certifique-se de ter o seguinte instalado:

* **Python 3.8+**
* **pip** (instalador de pacotes Python)

### Instala√ß√£o

1.  **Clone o reposit√≥rio (ou salve o c√≥digo):**
    Se o seu c√≥digo estiver em um arquivo, salve-o como `app.py` (ou qualquer outra extens√£o `.py`). Se for parte de um reposit√≥rio Git, clone-o:
    ```bash
    git clone <url_do_seu_repositorio>
    cd <diretorio_do_seu_repositorio>
    ```

2.  **Instale os pacotes Python necess√°rios:**
    Crie um arquivo `requirements.txt` no mesmo diret√≥rio do seu script Python com o seguinte conte√∫do:

    ```
    openai
    pandas
    gradio
    dspy-ai
    ```

    Em seguida, instale-os usando pip:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure sua Chave de API OpenAI:**
    A aplica√ß√£o requer uma chave de API OpenAI para interagir com o modelo GPT.
    Voc√™ precisa definir a vari√°vel `openai.api_key` em seu c√≥digo. **Substitua o placeholder pela sua chave de API real:**

    ```python
    openai.api_key = "SUA_CHAVE_DE_API_OPENAI_AQUI"
    ```
    **Importante:** Para ambientes de produ√ß√£o, √© altamente recomend√°vel usar vari√°veis de ambiente para armazenar sua chave de API por motivos de seguran√ßa (por exemplo, `os.environ.get("OPENAI_API_KEY")`).

---

## üõ†Ô∏è Como Usar

1.  **Execute a aplica√ß√£o:**
    Abra seu terminal ou prompt de comando, navegue at√© o diret√≥rio do projeto e execute o script Python:
    ```bash
    python app.py
    ```

2.  **Acesse a interface web:**
    Voc√™ pode acessar a interface do Gradio localmente (o link ser√° exibido no seu terminal, geralmente `http://127.0.0.1:7860`) ou atrav√©s do link de compartilhamento p√∫blico fornecido abaixo.

    ---
    **Link para acessar a interface do Gradio e fazer perguntas a respeito dos dados carregados:**
    [https://9cd92c0aa2a947883d.gradio.live/](https://9cd92c0aa2a947883d.gradio.live/)
    ---

3.  **Envie seu arquivo ZIP:**
    Na interface do Gradio, clique no componente "Fa√ßa upload do arquivo ZIP" e selecione um arquivo `.zip` contendo um ou mais arquivos CSV (como o `202401_NFs.zip` mencionado no contexto do desafio).

4.  **Processe o arquivo ZIP:**
    Clique no bot√£o "Processar ZIP". A aplica√ß√£o extrair√° os CSVs e os carregar√° em DataFrames do pandas. A caixa de texto "Status" mostrar√° quantos arquivos CSV foram carregados.

5.  **Fa√ßa perguntas:**
    Depois que os CSVs forem carregados, voc√™ pode digitar suas perguntas sobre os dados na caixa de texto "Pergunta sobre os dados" e pressionar Enter (ou clicar fora da caixa de texto). A IA fornecer√° uma resposta na caixa de texto "Resposta IA", utilizando os dados carregados como contexto.

---

## ‚öôÔ∏è Como Funciona

A aplica√ß√£o combina v√°rias bibliotecas poderosas para alcan√ßar sua funcionalidade:

* **`zipfile` e `shutil`:** Usados para manipula√ß√£o de arquivos ZIP, extra√ß√£o e gerenciamento de diret√≥rios tempor√°rios.
* **`pandas`:** Essencial para ler e manipular dados CSV, armazenando-os em DataFrames.
* **`openai` e `dspy`:**
    * `openai` fornece a interface direta para a API da OpenAI.
    * `dspy` (Declarative Self-improving Language Programs) √© usado para estruturar a engenharia de prompt e a intera√ß√£o com o LLM. Ele define uma `Signature` (`AskCSV`) que especifica claramente as entradas (`question`, `context`) e a sa√≠da (`answer`), tornando a tarefa do LLM bem definida.
    * O `AskCSVModule` encapsula essa `Signature` para f√°cil invoca√ß√£o.
    * O modelo `gpt-4.1-mini` √© configurado com uma `temperature` baixa (0.0) para respostas mais determin√≠sticas e factuais, e um `max_tokens` alto (20000) para permitir respostas abrangentes.
* **`gradio`:** Fornece a interface web amig√°vel. Ele simplifica a cria√ß√£o de componentes interativos para upload de arquivos, entradas de texto e bot√µes, conectando-os √†s fun√ß√µes Python de backend.

### L√≥gica Central

1.  **Upload e Processamento de Arquivos (`process_zip`):**
    * Quando um usu√°rio faz upload de um arquivo ZIP, ele √© salvo temporariamente e extra√≠do para o diret√≥rio `uploaded_data`.
    * A fun√ß√£o ent√£o percorre os arquivos extra√≠dos, identificando e lendo todos os arquivos `.csv` em DataFrames do pandas.
    * Uma coluna `__source_file` √© adicionada a cada DataFrame para rastrear sua origem.
    * Esses DataFrames s√£o armazenados globalmente em `global_dataframes`.

2.  **Resposta a Perguntas (`ask_question`):**
    * Quando um usu√°rio envia uma pergunta, a fun√ß√£o primeiro verifica se algum CSV foi carregado.
    * Em seguida, ela constr√≥i um `context` pegando as 10 primeiras linhas de cada DataFrame carregado e convertendo-as em representa√ß√µes de string. Este contexto √© fornecido ao LLM.
    * O m√≥dulo `dspy` (`ask_module`) √© invocado com a `question` do usu√°rio e o `context` gerado.
    * O LLM processa essas informa√ß√µes e gera uma `answer`, que √© ent√£o exibida na interface do Gradio.

---

## üõë Limita√ß√µes

* **Context Window Limit:** Embora `gpt-4.1-mini` tenha uma grande janela de contexto, alimentar o conte√∫do inteiro de CSVs muito grandes pode exced√™-la. Atualmente, apenas as 10 primeiras linhas de cada DataFrame s√£o usadas como contexto. Para conjuntos de dados maiores, seria necess√°ria uma recupera√ß√£o de contexto mais sofisticada (por exemplo, usando embeddings e bancos de dados vetoriais).
* **Interpreta√ß√£o de Dados:** A qualidade da resposta da IA depende muito da clareza da pergunta e da representatividade do contexto fornecido.
* **Seguran√ßa:** Armazenar chaves de API diretamente no c√≥digo n√£o √© recomendado para ambientes de produ√ß√£o.

---

## üë• Membros do Grupo ProcessON

* Aurilene Ribeiro
* Eduardo Orlando
* Eric Bueno
* Felipe Moura
* Jo√£o Vitor
* Leonardo Santos
* Let√≠cia Machado
* Marco Andrey
* Pascual Matheo
* Sandro Costa

---

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Se voc√™ tiver sugest√µes para melhorias ou novos recursos, sinta-se √† vontade para abrir uma *issue* ou enviar um *pull request*.

---

## üìÑ Licen√ßa

Este projeto √© de c√≥digo aberto e est√° dispon√≠vel sob a [Licen√ßa MIT](LICENSE) (se voc√™ tiver uma, caso contr√°rio, remova esta se√ß√£o).