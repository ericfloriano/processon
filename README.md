# üß† ProcessON - I2A2 | Consulta de Dados CSV por Agente

Este projeto oferece uma interface interativa para processar e consultar dados de m√∫ltiplos arquivos CSV e XLSX, incluindo aqueles contidos em arquivos ZIP. Ele aproveita o poder dos Modelos de Linguagem Grandes (LLMs) via biblioteca `langchain` e `Gradio` para uma interface web amig√°vel, permitindo responder a perguntas em linguagem natural sobre os dados carregados de forma mais robusta e completa, utilizando um agente de DataFrames do LangChain.

---

## üéØ Contexto do Desafio I2A2

Esta atividade faz parte do curso I2A2 e tem como objetivo principal **criar um ou mais agentes que permitam a um usu√°rio realizar perguntas sobre arquivos CSV e/ou XLSX disponibilizados**.

Por exemplo, os usu√°rios podem perguntar:
* "Qual √© o fornecedor que teve maior montante recebido?"
* "Qual item teve maior volume entregue (em quantidade)?"
* "Qual o valor total gasto pelo 'MINISTERIO DA SAUDE'?"
* "Em qual dia da semana (segunda, ter√ßa, etc.) a maioria das notas fiscais foi emitida?"
* "Qual empresa vendeu mais livros?"
* "Para cada estado de destino (UF DESTINAT√ÅRIO), qual foi o valor total comprado e o n√∫mero total de itens √∫nicos adquiridos?"
* E assim por diante, explorando os dados de forma conversacional e complexa.

### Recursos Utilizados

Para este desafio, √© fornecido um arquivo de exemplo chamado `202401_NFs.zip`. Este arquivo cont√©m:

* **`202401_NFs_Cabecalho.csv`**: O cabe√ßalho de 100 notas fiscais selecionadas aleatoriamente do arquivo de notas fiscais do m√™s de janeiro/2024, disponibilizado pelo Tribunal de Contas da Uni√£o.
* **`202401_NFs_Itens.csv`**: Os itens correspondentes das 100 notas fiscais selecionadas.

Ambos os arquivos est√£o em formato CSV. Os campos est√£o separados por v√≠rgulas e o separador de casas decimais dos valores num√©ricos √© ponto. As datas est√£o no formato AAAA-MM-DD HH:MN:SS.

---

## üöÄ Primeiros Passos

Siga estas instru√ß√µes para configurar e executar o projeto localmente.

### Pr√©-requisitos

Antes de come√ßar, certifique-se de ter o seguinte instalado:

* **Python 3.8+**
* **pip** (instalador de pacotes Python)

### Instala√ß√£o

1.  **Clone o reposit√≥rio (ou salve o c√≥digo):**
    Se o seu c√≥digo estiver em um arquivo, salve-o como `main.py`. Se for parte de um reposit√≥rio Git, clone-o:
    ```bash
    git clone <url_do_seu_repositorio>
    cd <diretorio_do_seu_repositorio>
    ```

2.  **Crie o arquivo `config.py`:**
    Crie um arquivo chamado `config.py` no mesmo diret√≥rio do seu script `main.py` com o seguinte conte√∫do:
    ```python
    # config.py
    # Substitua a string abaixo pela sua chave de API da OpenAI.
    OPENAI_API_KEY = "SUA_CHAVE_DE_API_OPENAI_AQUI"
    ```

3.  **Instale os pacotes Python necess√°rios:**
    Crie um arquivo `requirements.txt` no mesmo diret√≥rio do seu script Python com o seguinte conte√∫do:

    ```
    gradio
    pandas
    langchain-openai
    langchain-experimental
    tabulate
    openpyxl
    ```

    Em seguida, instale-os usando pip:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure sua Chave de API OpenAI:**
    A aplica√ß√£o requer uma chave de API OpenAI para interagir com o modelo GPT.
    Voc√™ precisa definir a vari√°vel `OPENAI_API_KEY` no arquivo `config.py` conforme instru√≠do no passo 2.

    **Importante:** Para ambientes de produ√ß√£o, √© altamente recomend√°vel usar vari√°veis de ambiente para armazenar sua chave de API por motivos de seguran√ßa (por exemplo, `os.environ.get("OPENAI_API_KEY")`).

---

## üõ†Ô∏è Como Usar

1.  **Execute a aplica√ß√£o:**
    Abra seu terminal ou prompt de comando, navegue at√© o diret√≥rio do projeto e execute o script Python:
    ```bash
    python main.py
    ```

2.  **Acesse a interface web:**
    Voc√™ pode acessar a interface do Gradio localmente (o link ser√° exibido no seu terminal, geralmente `http://127.0.0.1:7860`) ou atrav√©s de um link de compartilhamento p√∫blico (como `https://42d389f99c5f2f062f.gradio.live/` exemplificado nos logs, que expira em 1 semana).

3.  **Envie seus arquivos:**
    Na interface do Gradio, clique no componente "Fa√ßa upload de seus arquivos de dados" e selecione um ou mais arquivos `.zip`, `.csv` ou `.xlsx`.

4.  **Processar os arquivos:**
    Clique no bot√£o "Processar Arquivos". A aplica√ß√£o extrair√° os arquivos (se for um ZIP) e os carregar√° em DataFrames do pandas. A caixa de texto "Status do Processamento" mostrar√° quais arquivos foram carregados.

5.  **Fa√ßa perguntas:**
    Depois que os dados forem carregados, voc√™ pode digitar suas perguntas sobre os dados na caixa de texto "Fa√ßa sua pergunta sobre os dados" e pressionar Enter (ou clicar fora da caixa de texto). A IA, atrav√©s do agente LangChain, fornecer√° uma resposta na caixa de texto "Resposta da IA", utilizando os dados carregados como contexto.

---

## ‚öôÔ∏è Como Funciona

A aplica√ß√£o combina v√°rias bibliotecas poderosas para alcan√ßar sua funcionalidade:

* **`zipfile` e `shutil`:** Usados para manipula√ß√£o de arquivos ZIP, extra√ß√£o e gerenciamento de diret√≥rios tempor√°rios.
* **`pandas`:** Essencial para ler e manipular dados CSV/XLSX, armazenando-os em DataFrames.
* **`langchain_openai` e `langchain_experimental`:**
    * `ChatOpenAI`: Fornece a interface para a API da OpenAI (`gpt-4.1-mini` √© o modelo utilizado).
    * `create_pandas_dataframe_agent`: Uma ferramenta poderosa do LangChain que permite que um LLM interaja com um ou m√∫ltiplos DataFrames do pandas, executando opera√ß√µes para responder a perguntas complexas. Ele √© capaz de raciocinar sobre os dados e gerar c√≥digo Python para extrair as informa√ß√µes necess√°rias.
* **`gradio`:** Fornece a interface web amig√°vel e interativa, simplificando a cria√ß√£o de componentes para upload de arquivos, entradas de texto e bot√µes, conectando-os √†s fun√ß√µes Python de backend.

### L√≥gica Central

1.  **Upload e Processamento de Arquivos (`process_files`):**
    * Quando o usu√°rio faz upload de arquivos (ZIP, CSV ou XLSX), eles s√£o salvos temporariamente.
    * Se for um arquivo ZIP, seu conte√∫do √© extra√≠do para o diret√≥rio `uploaded_data`.
    * Todos os arquivos `.csv` e `.xlsx` encontrados (seja diretamente ou dentro do ZIP) s√£o lidos em DataFrames do pandas.
    * Esses DataFrames s√£o armazenados em um dicion√°rio global (`global_dfs`), com nomes limpos (`df_cabecalho`, `df_itens`, etc.) para f√°cil refer√™ncia pelo agente.

2.  **Resposta a Perguntas (`ask_question`):**
    * Verifica se os dados foram carregados e se a chave de API da OpenAI est√° configurada.
    * Inicializa o modelo `ChatOpenAI` com `temperature=0` para respostas mais determin√≠sticas e factuais.
    * Cria um `create_pandas_dataframe_agent` do LangChain, passando a lista de DataFrames carregados. O agente √© configurado com `verbose=True` para mostrar o racioc√≠nio e as a√ß√µes tomadas pelo LLM e `allow_dangerous_code=True` para permitir a execu√ß√£o de c√≥digo Python gerado pelo agente.
    * Um `instruction_prefix` √© constru√≠do para informar o agente sobre os nomes dos DataFrames carregados (`df_cabecalho`, `df_itens`), permitindo que ele se refira a eles corretamente (`df1`, `df2`, etc.).
    * A pergunta do usu√°rio √© combinada com o prefixo de instru√ß√£o e passada para o agente via `agent.invoke()`.
    * O agente utiliza o LLM para raciocinar, gerar e executar o c√≥digo Python necess√°rio nos DataFrames para responder √† pergunta.
    * A resposta gerada pelo agente √© ent√£o exibida na interface do Gradio.

---

## üõë Limita√ß√µes

* **Custos da API OpenAI:** O uso do modelo `gpt-4.1-mini` (ou qualquer outro modelo pago da OpenAI) incorre em custos. O uso excessivo pode gerar despesas significativas.
* **Token Limit (Context Window):** Embora os modelos GPT tenham janelas de contexto grandes, processar datasets muito extensos pode ainda exceder esses limites. O agente LangChain √© mais eficiente em manipular grandes DataFrames internamente, mas o volume de sa√≠da do c√≥digo Python e o racioc√≠nio do LLM ainda consomem tokens.
* **Complexidade da Pergunta:** Perguntas muito amb√≠guas ou que exigem um racioc√≠nio complexo demais podem desafiar a capacidade do agente de gerar o c√≥digo Python correto.
* **Seguran√ßa:** Armazenar chaves de API diretamente no c√≥digo ou em arquivos de configura√ß√£o n√£o √© recomendado para ambientes de produ√ß√£o. O ideal √© usar vari√°veis de ambiente ou servi√ßos de gerenciamento de segredos.
* **Depend√™ncia Externa:** A funcionalidade do projeto depende da disponibilidade e do desempenho da API da OpenAI.

---

## üë• Membros do Grupo ProcessON

* Aurilene Ribeiro
* Eduardo Orlando
* Eric Bueno
* Felipe Moura
* Jo√£o Vitor
* Leonardo Santos
* Let√≠cia Machado
* Marco Andrey
* Pascual Matheo
* Sandro Costa

---

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Se voc√™ tiver sugest√µes para melhorias ou novos recursos, sinta-se √† vontade para abrir uma *issue* ou enviar um *pull request*.

---

## üìÑ Licen√ßa

Este projeto √© de c√≥digo aberto e est√° dispon√≠vel sob a [Licen√ßa MIT](LICENSE.txt).